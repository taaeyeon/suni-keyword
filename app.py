# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JgDVDP0yIv2yTgQimMccm71kmIKab7Vb
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from konlpy.tag import Okt
from collections import Counter
import re
from wordcloud import WordCloud

# âœ… ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="í‚¤ì›Œë“œ ë¶„ì„", layout="wide")
st.title("ğŸ“Š SUNI í‚¤ì›Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# âœ… íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (.xlsx)", type="xlsx")

# âœ… ë¶„ì„ ìœ í˜• ì„ íƒ
analysis_type = st.radio("ë¶„ì„ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”", ["ì „ì‚¬", "ì§ë¬´ë³„"])

# âœ… í°íŠ¸ ê²½ë¡œ (ì›Œë“œí´ë¼ìš°ë“œìš©, ì‹œìŠ¤í…œì— ë”°ë¼ ìˆ˜ì • í•„ìš”)
FONT_PATH = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"

# âœ… ë¶„ì„ ì‹¤í–‰
if uploaded_file:
    df = pd.read_excel(uploaded_file)
    df_focus = df.copy()  # ì›ë³¸ ë³´ì¡´

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    if 'ì§ë¬´' not in df_focus.columns or '(2) ì„±ì¥/ì—­ëŸ‰/ì»¤ë¦¬ì–´-êµ¬ì„±ì› ì˜ê²¬' not in df_focus.columns:
        st.error("ì—‘ì…€ íŒŒì¼ì— 'ì§ë¬´' ë° '(2) ì„±ì¥/ì—­ëŸ‰/ì»¤ë¦¬ì–´-êµ¬ì„±ì› ì˜ê²¬' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        # í˜•íƒœì†Œ ë¶„ì„ê¸° ë° ë¶ˆìš©ì–´
        okt = Okt()
        stopwords = set([
            'ìœ„í•´', 'ê´€ë ¨', 'ê°•í™”', 'ê¸°ë°˜', 'ë°', 'ìˆ˜ì¤€', 'í•„ìš”', 'ì œì•ˆ', 'ë°©ì•ˆ', 'í™œìš©',
            'ì°¸ì„', 'êµìœ¡', 'ì§„í–‰', 'ì—­ëŸ‰', 'ë‚´ìš©', 'ì´í•´', 'ì œê³ ', 'í™•ë³´', 'ëŒ€í•œ', 'ìˆìŠµë‹ˆë‹¤',
            'ìˆë„ë¡', 'ìœ„í•œ', 'í•˜ê³ ', 'ì‹¶ìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'í†µí•´', 'í•œë²ˆ', 'í•˜ëŠ”', 'ê°™ì€', 'ë³´ì—¬', 'ëœë‹¤', 'ìˆ˜í–‰'
        ])

        def clean_and_tokenize(texts):
            combined = ' '.join(texts)
            clean = re.sub(r"[^ê°€-í£\s]", "", combined)
            nouns = okt.nouns(clean)
            filtered = [word for word in nouns if word not in stopwords and len(word) > 1]
            return Counter(filtered)

        def draw_charts(title, freq_dict):
            col1, col2 = st.columns(2)

            with col1:
                st.subheader(f"ğŸ“Š {title} - ë§‰ëŒ€ê·¸ë˜í”„")
                fig, ax = plt.subplots()
                ax.bar(freq_dict.keys(), freq_dict.values(), color='skyblue')
                plt.xticks(rotation=45)
                st.pyplot(fig)

            with col2:
                st.subheader(f"ğŸ§ {title} - íŒŒì´ì°¨íŠ¸")
                fig, ax = plt.subplots()
                ax.pie(freq_dict.values(), labels=freq_dict.keys(), autopct='%1.1f%%', startangle=140)
                st.pyplot(fig)

            st.subheader(f"â˜ï¸ {title} - ì›Œë“œí´ë¼ìš°ë“œ")
            wc = WordCloud(font_path=FONT_PATH, background_color='white', width=800, height=400)
            wc.generate_from_frequencies(freq_dict)
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wc, interpolation='bilinear')
            ax.axis("off")
            st.pyplot(fig)

        # ì „ì‚¬ ë¶„ì„
        if analysis_type == "ì „ì‚¬":
            texts = df_focus['(2) ì„±ì¥/ì—­ëŸ‰/ì»¤ë¦¬ì–´-êµ¬ì„±ì› ì˜ê²¬'].dropna().tolist()
            counter = clean_and_tokenize(texts)
            top50 = dict(counter.most_common(50))
            draw_charts("ì „ì‚¬ í‚¤ì›Œë“œ", top50)

        # ì§ë¬´ë³„ ë¶„ì„
        else:
            results = []
            for job, group in df_focus.groupby("ì§ë¬´"):
                texts = group['(2) ì„±ì¥/ì—­ëŸ‰/ì»¤ë¦¬ì–´-êµ¬ì„±ì› ì˜ê²¬'].dropna().tolist()
                counter = clean_and_tokenize(texts)
                top10 = dict(counter.most_common(10))
                results.append((job, top10))

            for job, freq_dict in results:
                st.markdown(f"### ğŸ” ì§ë¬´: {job}")
                draw_charts(job, freq_dict)