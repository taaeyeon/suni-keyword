# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JgDVDP0yIv2yTgQimMccm71kmIKab7Vb
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import re
from wordcloud import WordCloud

# âœ… ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="í‚¤ì›Œë“œ ë¶„ì„", layout="wide")
st.title("ğŸ“Š SUNI í‚¤ì›Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# âœ… íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (.xlsx)", type="xlsx")

# âœ… ë¶„ì„ ìœ í˜• ì„ íƒ
analysis_type = st.radio("ë¶„ì„ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”", ["ì „ì‚¬", "ì§ë¬´ë³„"])

# âœ… í°íŠ¸ ê²½ë¡œ (ì›Œë“œí´ë¼ìš°ë“œìš©)
FONT_PATH = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"

# âœ… ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ (ì§ì ‘ ì •ì˜)
stopwords = set([
    'ìœ„í•´', 'ê´€ë ¨', 'ê°•í™”', 'ê¸°ë°˜', 'ë°', 'ìˆ˜ì¤€', 'í•„ìš”', 'ì œì•ˆ', 'ë°©ì•ˆ', 'í™œìš©',
    'ì°¸ì„', 'êµìœ¡', 'ì§„í–‰', 'ì—­ëŸ‰', 'ë‚´ìš©', 'ì´í•´', 'ì œê³ ', 'í™•ë³´', 'ëŒ€í•œ', 'ìˆìŠµë‹ˆë‹¤',
    'ìˆë„ë¡', 'ìœ„í•œ', 'í•˜ê³ ', 'ì‹¶ìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'í†µí•´', 'í•œë²ˆ', 'í•˜ëŠ”', 'ê°™ì€', 'ë³´ì—¬', 'ëœë‹¤', 'ìˆ˜í–‰'
])

# âœ… ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì •ì œ ë° í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
def extract_keywords(texts):
    text = ' '.join(texts)
    text = re.sub(r"[^ê°€-í£\s]", "", text)  # í•œê¸€ë§Œ ë‚¨ê¹€
    words = text.split()
    filtered = [w for w in words if w not in stopwords and len(w) > 1]
    return Counter(filtered)

# âœ… ì‹œê°í™” í•¨ìˆ˜
def draw_charts(title, freq_dict):
    col1, col2 = st.columns(2)

    with col1:
        st.subheader(f"ğŸ“Š {title} - ë§‰ëŒ€ê·¸ë˜í”„")
        fig, ax = plt.subplots()
        ax.bar(freq_dict.keys(), freq_dict.values(), color='skyblue')
        plt.xticks(rotation=45)
        st.pyplot(fig)

    with col2:
        st.subheader(f"ğŸ§ {title} - íŒŒì´ì°¨íŠ¸")
        fig, ax = plt.subplots()
        ax.pie(freq_dict.values(), labels=freq_dict.keys(), autopct='%1.1f%%', startangle=140)
        st.pyplot(fig)

    st.subheader(f"â˜ï¸ {title} - ì›Œë“œí´ë¼ìš°ë“œ")
    wc = WordCloud(font_path=FONT_PATH, background_color='white', width=800, height=400)
    wc.generate_from_frequencies(freq_dict)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wc, interpolation='bilinear')
    ax.axis("off")
    st.pyplot(fig)

# âœ… ë¶„ì„ ì‹¤í–‰
if uploaded_file:
    df = pd.read_excel(uploaded_file)
    df_focus = df.copy()

    if 'ì§ë¬´' not in df_focus.columns or '(2) ì„±ì¥/ì—­ëŸ‰/ì»¤ë¦¬ì–´-êµ¬ì„±ì› ì˜ê²¬' not in df_focus.columns:
        st.error("ì—‘ì…€ íŒŒì¼ì— 'ì§ë¬´' ë° '(2) ì„±ì¥/ì—­ëŸ‰/ì»¤ë¦¬ì–´-êµ¬ì„±ì› ì˜ê²¬' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        if analysis_type == "ì „ì‚¬":
            texts = df_focus['(2) ì„±ì¥/ì—­ëŸ‰/ì»¤ë¦¬ì–´-êµ¬ì„±ì› ì˜ê²¬'].dropna().tolist()
            counter = extract_keywords(texts)
            top50 = dict(counter.most_common(50))
            draw_charts("ì „ì‚¬ í‚¤ì›Œë“œ", top50)
        else:
            results = []
            for job, group in df_focus.groupby("ì§ë¬´"):
                texts = group['(2) ì„±ì¥/ì—­ëŸ‰/ì»¤ë¦¬ì–´-êµ¬ì„±ì› ì˜ê²¬'].dropna().tolist()
                counter = extract_keywords(texts)
                top10 = dict(counter.most_common(10))
                results.append((job, top10))

            for job, freq_dict in results:
                st.markdown(f"### ğŸ” ì§ë¬´: {job}")
                draw_charts(job, freq_dict)